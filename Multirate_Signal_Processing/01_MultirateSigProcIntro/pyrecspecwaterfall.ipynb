{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pyrecspecwaterfall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Pyaudio, record sound from the audio device and plot a waterfall spectrum display, for 8 seconds.\n",
    "\n",
    "Usage example: python pyrecspecwaterfall.py\n",
    "\n",
    "    - Gerald Schuller, November 2014"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Import the relevant modules:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import struct\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Define the variables:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CHUNK = 2048 #Blocksize\n",
    "WIDTH = 2 #2 bytes per sample\n",
    "CHANNELS = 1 #2\n",
    "RATE = 48000  #Sampling Rate in Hz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Initialise the sound card print out its detail:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('device count=', 3L)\n",
      "('i = ', 0)\n",
      "2\n",
      "44100.0\n",
      "('i = ', 1)\n",
      "32\n",
      "44100.0\n",
      "('i = ', 2)\n",
      "32\n",
      "44100.0\n",
      "* recording\n"
     ]
    }
   ],
   "source": [
    "p = pyaudio.PyAudio()\n",
    "\n",
    "a = p.get_device_count()\n",
    "print(\"device count=\",a)\n",
    "\n",
    "for i in range(0, a):\n",
    "    print(\"i = \",i)\n",
    "    b = p.get_device_info_by_index(i)['maxInputChannels']\n",
    "    print(b)\n",
    "    b = p.get_device_info_by_index(i)['defaultSampleRate']\n",
    "    print(b)\n",
    "\n",
    "stream = p.open(format=p.get_format_from_width(WIDTH),\n",
    "                channels=CHANNELS,\n",
    "                rate=RATE,\n",
    "                input=True,\n",
    "                output=True,\n",
    "                #input_device_index=3,\n",
    "                frames_per_buffer=CHUNK)\n",
    "\n",
    "\n",
    "print(\"* recording\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Size of waterfall diagram:**\n",
    "* **max CHUNK/2 rows:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rows = 500\n",
    "cols = 512\n",
    "fftlen = cols * 2\n",
    "frame = 0.0 * np.ones((rows, cols, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Start recording and plotting the real time spectrogram waterfall(upward) which shows the intensities but the colours in the row and time vertically moving upward. The steps involve the block wise prcessing of the recorded samples and then show its spectrogram in row.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ctr = 0\n",
    "while(True):\n",
    "    ctr = ctr + 1\n",
    "    #Reading from audio input stream into data with block length \"CHUNK\":\n",
    "    data = stream.read(CHUNK)\n",
    "    #Convert from stream of bytes to a list of short integers (2 bytes here) in \"samples\":\n",
    "    #shorts = (struct.unpack( \"128h\", data ))\n",
    "    shorts = (struct.unpack( 'h' * CHUNK, data ));\n",
    "    samples = np.array(list(shorts), dtype=float);\n",
    "\n",
    "    if (ctr%4 == 0):\n",
    "        #shift \"frame\" 1 up:\n",
    "        frame[0:(rows-1),:]=frame[1:rows,:];\n",
    "        #compute magnitude of 1D FFT of sound\n",
    "        #with suitable normalization for the display:\n",
    "        #frame=np.abs(np.ffqt.fft2(frame[:,:,1]/255.0))/512.0\n",
    "        #write magnitude spectrum in lowes row of \"frame\":\n",
    "        R = 0.25 * np.log((np.abs(np.fft.fft(samples[0:fftlen])[0:(fftlen/2)]/np.sqrt(fftlen))+1))/np.log(10.0)\n",
    "        #Color mapping:\n",
    "        #Red:\n",
    "        frame[rows-1,:,2] = R\n",
    "        #Green:\n",
    "        frame[rows-1,:,1] = np.abs(1-2*R)\n",
    "        #Blue:\n",
    "        frame[rows-1,:,0] = 1.0-R\n",
    "        #frame[rows-1,:,0]=frame[rows-1,:,1]**3\n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('frame',frame)\n",
    "    #Keep window open until key 'q' is pressed:\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **When everything's done then release the capture:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()\n",
    "\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "p.terminate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
