{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This program shows the characteristics of the audio recorded via a waterfall(going up) spectrogram where the horizontal shows the frequencies for the coreesponding block of the recording and the vertical axis is the time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input: \n",
    "As the program runs the recording starts and wait for thr user inputs from the keyboard. Below are the key inputs and their effects:\n",
    "### 's' - turn on/off the sampling\n",
    "### 'f' - turn on/off the filtering (to remove aliasing)\n",
    "### 'q' - quit the recording and hence the program(program will not end by clicking close on the window, so instead press 'q')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output: \n",
    "Real time audio spectrogram for the processed blocks of the recording moving upward(like an upside down waterfall)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import relevant modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Using Pyaudio, record sound from the audio device and plot a waterfall spectrum display, and sample and output the signal with \n",
    "aliasing. It includes a low pass filter for aliasing reduction.\n",
    "Filtering and sampling can be toggled on and off using the key 'f' for filter on/off, and 's' for sampling on/off, to show the \n",
    "differences. Use key 'q' to quit.\n",
    "Usage example: python pyrecspecwaterfallsampling.py\n",
    "Gerald Schuller, August 2015 \n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "import pyaudio\n",
    "import struct\n",
    "import numpy as np\n",
    "import scipy.signal\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CHUNK = 2048 #Blocksize\n",
    "WIDTH = 2 #2 bytes per sample\n",
    "CHANNELS = 1 #2\n",
    "RATE = 32000  #Sampling Rate in Hz\n",
    "N=8.0;    #sampling rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize the sound card and print out audio input and output properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('device count=', 16L)\n",
      "('i = ', 0)\n",
      "2\n",
      "44100.0\n",
      "('i = ', 1)\n",
      "2\n",
      "44100.0\n",
      "('i = ', 2)\n",
      "0\n",
      "44100.0\n",
      "('i = ', 3)\n",
      "0\n",
      "44100.0\n",
      "('i = ', 4)\n",
      "0\n",
      "44100.0\n",
      "('i = ', 5)\n",
      "2\n",
      "44100.0\n",
      "('i = ', 6)\n",
      "2\n",
      "44100.0\n",
      "('i = ', 7)\n",
      "0\n",
      "44100.0\n",
      "('i = ', 8)\n",
      "0\n",
      "44100.0\n",
      "('i = ', 9)\n",
      "0\n",
      "44100.0\n",
      "('i = ', 10)\n",
      "0\n",
      "44100.0\n",
      "('i = ', 11)\n",
      "0\n",
      "44100.0\n",
      "('i = ', 12)\n",
      "2\n",
      "44100.0\n",
      "('i = ', 13)\n",
      "0\n",
      "44100.0\n",
      "('i = ', 14)\n",
      "2\n",
      "44100.0\n",
      "('i = ', 15)\n",
      "0\n",
      "44100.0\n"
     ]
    }
   ],
   "source": [
    "p = pyaudio.PyAudio()\n",
    "\n",
    "a = p.get_device_count()\n",
    "print(\"device count=\",a)\n",
    "\n",
    "for i in range(0, a):\n",
    "    print(\"i = \",i)\n",
    "    b = p.get_device_info_by_index(i)['maxInputChannels']\n",
    "    print(b)\n",
    "    b = p.get_device_info_by_index(i)['defaultSampleRate']\n",
    "    print(b)\n",
    "\n",
    "stream = p.open(format=p.get_format_from_width(WIDTH),\n",
    "                channels=CHANNELS,\n",
    "                rate=RATE,\n",
    "                input=True,\n",
    "                output=True,\n",
    "                #input_device_index=3,\n",
    "                frames_per_buffer=CHUNK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Designing an IIR filter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Our Lowpass Filter:\n",
    "[b,a]=scipy.signal.iirfilter(4, 1900.0/16000,rp=60,btype='lowpass')\n",
    "#Memory for the filter:\n",
    "zd=np.zeros(5-1)\n",
    "zu=np.zeros(5-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Program to demonstrate audio aliasing and anti-aliasing filtering\n",
      "Downsampling factor: N=8\n",
      "Toggle filter before and after sampling on/off: press key 'f'\n",
      "Toggle sampling on/off: press key 's'\n",
      "To quit press key 'q'\n"
     ]
    }
   ],
   "source": [
    "print(\"Program to demonstrate audio aliasing and anti-aliasing filtering\")\n",
    "print(\"Downsampling factor: N=8\")\n",
    "print(\"Toggle filter before and after sampling on/off: press key 'f'\")\n",
    "print(\"Toggle sampling on/off: press key 's'\")\n",
    "print(\"To quit press key 'q'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recording audio and displaying waterfall for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* recording\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python27\\lib\\site-packages\\ipykernel\\__main__.py:56: DeprecationWarning: integer argument expected, got float\n"
     ]
    }
   ],
   "source": [
    "print(\"* recording\")\n",
    "#Size of waterfall diagramm:\n",
    "#max CHUNK/2 rows:\n",
    "rows=500\n",
    "cols=512\n",
    "fftlen=cols*2\n",
    "frame=0.0*np.ones((rows,cols,3));\n",
    "frametxt=frame.copy()\n",
    "\n",
    "filteron=False\n",
    "downsampleon=False\n",
    "ctr=0\n",
    "cv2.putText(frame,\"Audio Spectrogram\", (20,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,128,128))\n",
    "cv2.putText(frame,\"Toggle sampling on/off: key s\", (20,100), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,128,128))\n",
    "cv2.putText(frame,\"(downsampling followed by upsampling)\", (20,150), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,128,128))\n",
    "cv2.putText(frame,\"Toggle LP Filter: key f\", (20,200), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,128,128))\n",
    "cv2.putText(frame,\"(LP filter before and after sampling)\", (20,250), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,128,128))\n",
    "cv2.putText(frame,\"Quit: key q\", (20,300), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,128,128))\n",
    "cv2.putText(frame,\"Sampling Freq.=\"+str(RATE)+\"Hz\", (20,350), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,128,128))\n",
    "cv2.putText(frame,\"Downsample Rate=\"+str(N), (20,400), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,128,128))\n",
    "\n",
    "while(True):\n",
    "    ctr=ctr+1  \n",
    "    #Reading from audio input stream into data with block length \"CHUNK\":\n",
    "    data = stream.read(CHUNK)\n",
    "    #Convert from stream of bytes to a list of short integers (2 bytes here) in \"samples\":\n",
    "    #shorts = (struct.unpack( \"128h\", data ))\n",
    "    shorts = (struct.unpack( 'h' * CHUNK, data ));\n",
    "    samples=np.array(list(shorts),dtype=float);\n",
    "\n",
    "    #start block-wise signal processing:\n",
    "    #Low pass filter *before downsampling*:\n",
    "    if filteron==True:\n",
    "       [samples,zd]=scipy.signal.lfilter(b, a, samples, zi=zd)\n",
    "\n",
    "    #Compute a block/an array of a unit pulse train corresponding a downsampling rate of N:\n",
    "\n",
    "    #s=np.modf(np.arange(0,CHUNK)/N)[0]==0.0\n",
    "    #make unit pulse train with modulus function \"%\": \n",
    "    s=(np.arange(0,CHUNK)%N)==0\n",
    "    #The sampling:\n",
    "    #multiply the signal with the unit pulse train:\n",
    "    if downsampleon == True:\n",
    "       samples=samples*s;\n",
    "    \n",
    "    #Lowpass filtering *after upsampling*:\n",
    "    #filter function:\n",
    "    if filteron==True:\n",
    "       [samples,zu]=scipy.signal.lfilter(b, a, samples, zi=zu)\n",
    "   \n",
    "    #end signal processing\n",
    "\n",
    "    #play out samples:\n",
    "    samples=np.clip(samples, -32000,32000)\n",
    "    #converting from short integers to a stream of bytes in \"data\":\n",
    "    data=struct.pack('h' * len(samples), *samples);\n",
    "    #Writing data back to audio output stream: \n",
    "    stream.write(data, CHUNK)\n",
    "\n",
    "    if (ctr%4 ==0):\n",
    "       #shift \"frame\" 1 up:\n",
    "       frame[0:(rows-1),:]=frame[1:rows,:]; \n",
    "       #compute magnitude of 1D FFT of sound \n",
    "       #with suitable normalization for the display:\n",
    "       #frame=np.abs(np.ffqt.fft2(frame[:,:,1]/255.0))/512.0\n",
    "       #write magnitude spectrum in lowes row of \"frame\":\n",
    "       R=0.25*np.log((np.abs(np.fft.fft(samples[0:fftlen])[0:(fftlen/2)]/np.sqrt(fftlen))+1))/np.log(10.0)\n",
    "       #Color mapping:\n",
    "       #Red:\n",
    "       frame[rows-1,:,2]=R\n",
    "       #Green:\n",
    "       frame[rows-1,:,1]=np.abs(1-2*R)\n",
    "       #Blue:\n",
    "       frame[rows-1,:,0]=1.0-R\n",
    "       #frame[rows-1,:,0]=frame[rows-1,:,1]**3\n",
    "       # Display the resulting frame\n",
    "       \n",
    "       cv2.imshow(\"Audio Spectrogram, filter: f, sampling: s, quit:q\",frame+frametxt)\n",
    "       \n",
    "    #Keep window open until key 'q' is pressed:\n",
    "    key=cv2.waitKey(1) & 0xFF;\n",
    "    if key == ord('f'):     \n",
    "       filteron= not filteron\n",
    "       cv2.putText(frame,\"filter=\"+str(filteron), (20,498), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,128,128))\n",
    "    if key == ord('s'):\n",
    "       downsampleon= not downsampleon \n",
    "       cv2.putText(frame,\"sampling=\"+str(downsampleon), (20,498), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,128,128))\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "# When everything done, release the capture\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "p.terminate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
